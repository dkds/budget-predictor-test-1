{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3080 Laptop GPU\n",
      "['../data/generated/generated_data_2.csv', '../data/generated/generated_data_3.csv', '../data/generated/generated_data_1.csv']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 32404 entries, 0 to 10854\n",
      "Data columns (total 20 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   Date                              32404 non-null  object \n",
      " 1   Transaction Category              32404 non-null  object \n",
      " 2   Amount                            32404 non-null  float64\n",
      " 3   Credit/Debit                      32404 non-null  object \n",
      " 4   Payment Method                    32404 non-null  object \n",
      " 5   Inflation Rate                    32404 non-null  float64\n",
      " 6   Dependent Family Size             32404 non-null  int64  \n",
      " 7   Age                               32404 non-null  int64  \n",
      " 8   Months with Higher Spending       32404 non-null  object \n",
      " 9   Number of Expenses a Month        32404 non-null  int64  \n",
      " 10  Most Frequent Expense Categories  32404 non-null  object \n",
      " 11  Estimated Monthly Expenses        32404 non-null  int64  \n",
      " 12  Day                               32404 non-null  int64  \n",
      " 13  Month                             32404 non-null  int64  \n",
      " 14  Year                              32404 non-null  int64  \n",
      " 15  Year-Month                        32404 non-null  object \n",
      " 16  Budget                            32404 non-null  float64\n",
      " 17  Cumulative Monthly Spending       32404 non-null  float64\n",
      " 18  Last Month Budget                 32404 non-null  float64\n",
      " 19  Average Monthly Budget            32404 non-null  float64\n",
      "dtypes: float64(6), int64(7), object(7)\n",
      "memory usage: 5.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import psutil\n",
    "import GPUtil\n",
    "import time\n",
    "\n",
    "gpu = GPUtil.getGPUs()[0]\n",
    "print(gpu.name)\n",
    "\n",
    "start_time = 0\n",
    "\n",
    "\n",
    "def log_resource_usage(scenario, timer_end):\n",
    "    global start_time\n",
    "    cpu_percent = psutil.cpu_percent(interval=1)\n",
    "    ram_mb = psutil.virtual_memory().used / (1024 ** 2)\n",
    "    gpu_usage = gpu.load * 100\n",
    "    gpu_ram_usage = gpu.memoryUsed\n",
    "    print(f\"{scenario}: CPU Usage: {cpu_percent}%\")\n",
    "    print(f\"{scenario}: RAM Usage: {round(ram_mb, 2)} MB\")\n",
    "    print(f\"{scenario}: GPU Usage: {round(gpu_usage, 2)}%\")\n",
    "    print(f\"{scenario}: GPU RAM Usage: {round(gpu_ram_usage, 2)} MB\")\n",
    "    if timer_end:\n",
    "        print(\n",
    "            f\"{scenario}: Execution time: {round(time.time() - start_time, 2)} seconds\")\n",
    "        start_time = 0\n",
    "    elif start_time == 0:\n",
    "        start_time = time.time()\n",
    "    return cpu_percent, ram_mb\n",
    "\n",
    "all_files = glob.glob(os.path.join('../data/generated/' , \"generated_*.csv\"))\n",
    "print(all_files)\n",
    "\n",
    "dataset = pd.DataFrame()\n",
    "for idx, filename in enumerate(all_files):\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    dataset = pd.concat([dataset, df])\n",
    "\n",
    "print(dataset.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207458.55789408716\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 32404 entries, 0 to 10854\n",
      "Data columns (total 12 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Transaction Category         32404 non-null  object \n",
      " 1   Amount                       32404 non-null  float64\n",
      " 2   Inflation Rate               32404 non-null  float64\n",
      " 3   Dependent Family Size        32404 non-null  int64  \n",
      " 4   Age                          32404 non-null  int64  \n",
      " 5   Estimated Monthly Expenses   32404 non-null  int64  \n",
      " 6   Day                          32404 non-null  float64\n",
      " 7   Month                        32404 non-null  float64\n",
      " 8   Year                         32404 non-null  float64\n",
      " 9   Cumulative Monthly Spending  32404 non-null  float64\n",
      " 10  Last Month Budget            32404 non-null  float64\n",
      " 11  Average Monthly Budget       32404 non-null  float64\n",
      "dtypes: float64(8), int64(3), object(1)\n",
      "memory usage: 3.2+ MB\n",
      "None\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index: 32404 entries, 0 to 10854\n",
      "Series name: Budget\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "32404 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 506.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Assume df is your DataFrame\n",
    "X = dataset.drop(['Budget', 'Date', 'Year-Month', 'Credit/Debit', 'Most Frequent Expense Categories',\n",
    "                 'Months with Higher Spending', 'Number of Expenses a Month', 'Payment Method'], axis=1)  # Features\n",
    "y = dataset['Budget']  # Labels\n",
    "\n",
    "# Perform Z-score normalization\n",
    "numeric_cols = ['Amount', 'Month', 'Year', 'Day', 'Last Month Budget',\n",
    "                'Cumulative Monthly Spending', 'Average Monthly Budget']\n",
    "for col in numeric_cols:\n",
    "    X[col] = (X[col] - X[col].mean()) / X[col].std()\n",
    "\n",
    "# If you want to normalize the label as well\n",
    "mean_budget = y.mean()\n",
    "std_budget = y.std()\n",
    "y = (y - mean_budget) / std_budget\n",
    "print(mean_budget)\n",
    "print(X.info())\n",
    "print(y.info())\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Create ColumnTransformer to apply OneHotEncoding only to the 'Transaction Category' column\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('desc_onehot', onehot_encoder, ['Transaction Category'])\n",
    "    ],\n",
    "    remainder='passthrough'  # keep remaining columns as is\n",
    ")\n",
    "\n",
    "# Fit and transform the training data and transform testing data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# X_train_onehot and X_test_onehot now contain the one-hot encoded 'Transaction Category' column along with other features.\n",
    "X_train_reshaped = X_train_transformed.reshape(\n",
    "    (X_train_transformed.shape[0], 1, X_train_transformed.shape[1]))\n",
    "X_test_reshaped = X_test_transformed.reshape(\n",
    "    (X_test_transformed.shape[0], 1, X_test_transformed.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre Training: CPU Usage: 0.1%\n",
      "Pre Training: RAM Usage: 11701.68 MB\n",
      "Pre Training: GPU Usage: 16.0%\n",
      "Pre Training: GPU RAM Usage: 15832.0 MB\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/50\n",
      "2593/2593 - 24s - loss: 62641.3555 - 24s/epoch - 9ms/step\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/neo/projects/jupyter/test-bank-data-1/models/lstm.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/projects/jupyter/test-bank-data-1/models/lstm.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m     best_model \u001b[39m=\u001b[39m KerasRegressor(model\u001b[39m=\u001b[39mcreate_model, learning_rate\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m], units\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39munits\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/projects/jupyter/test-bank-data-1/models/lstm.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m                             dropout_rate\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39mdropout_rate\u001b[39m\u001b[39m'\u001b[39m], epochs\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m], batch_size\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m], verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/projects/jupyter/test-bank-data-1/models/lstm.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m log_resource_usage(\u001b[39m\"\u001b[39m\u001b[39mPre Training\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/projects/jupyter/test-bank-data-1/models/lstm.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m best_model\u001b[39m.\u001b[39;49mfit(X_train_reshaped, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/projects/jupyter/test-bank-data-1/models/lstm.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m log_resource_usage(\u001b[39m\"\u001b[39m\u001b[39mPost Training\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/projects/jupyter/test-bank-data-1/models/lstm.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m best_model\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39msave(model_file)\n",
      "File \u001b[0;32m~/miniconda3/envs/bank-data-1/lib/python3.10/site-packages/scikeras/wrappers.py:760\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\n\u001b[1;32m    756\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfit__epochs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs)\n\u001b[1;32m    757\u001b[0m )\n\u001b[1;32m    758\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 760\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m    761\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    762\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    763\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    764\u001b[0m     warm_start\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwarm_start,\n\u001b[1;32m    765\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    766\u001b[0m )\n\u001b[1;32m    768\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/bank-data-1/lib/python3.10/site-packages/scikeras/wrappers.py:928\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_encoder_\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    926\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_model_compatibility(y)\n\u001b[0;32m--> 928\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_keras_model(\n\u001b[1;32m    929\u001b[0m     X,\n\u001b[1;32m    930\u001b[0m     y,\n\u001b[1;32m    931\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    932\u001b[0m     warm_start\u001b[39m=\u001b[39;49mwarm_start,\n\u001b[1;32m    933\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    934\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m    935\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    936\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/bank-data-1/lib/python3.10/site-packages/scikeras/wrappers.py:524\u001b[0m, in \u001b[0;36mBaseWrapper._fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m         hist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_\u001b[39m.\u001b[39mfit(x\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_args)\n\u001b[1;32m    523\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 524\u001b[0m     hist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_args)\n\u001b[1;32m    526\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m warm_start \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhistory_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m initial_epoch \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    527\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory_ \u001b[39m=\u001b[39m defaultdict(\u001b[39mlist\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/bank-data-1/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/bank-data-1/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/bank-data-1/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/bank-data-1/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/bank-data-1/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/bank-data-1/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/bank-data-1/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/bank-data-1/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/envs/bank-data-1/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/bank-data-1/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def create_model(learning_rate=0.01, units=50, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, input_shape=(\n",
    "        1, X_train_reshaped.shape[2]), activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model\n",
    "\n",
    "model_file = 'best_lstm_model'\n",
    "\n",
    "# if not os.path.exists(model_file):\n",
    "#     # Define hyperparameter grid\n",
    "#     learning_rate = [0.001, 0.01, 0.1]\n",
    "#     units = [30, 50, 70]\n",
    "#     dropout_rate = [0.0, 0.2, 0.4]\n",
    "#     batch_size = [10, 20, 30]\n",
    "#     epochs = [50, 100]\n",
    "#     param_dist = {\n",
    "#         'learning_rate': learning_rate,\n",
    "#         'units': units,\n",
    "#         'dropout_rate': dropout_rate,\n",
    "#         'batch_size': batch_size,\n",
    "#         'epochs': epochs\n",
    "#     }\n",
    "\n",
    "#     # Wrap the Keras model with KerasRegressor\n",
    "#     model = KerasRegressor(model=create_model, learning_rate=learning_rate, units=units,\n",
    "#                         dropout_rate=dropout_rate, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "#     # Use RandomizedSearchCV for hyperparameter tuning\n",
    "#     random_search = RandomizedSearchCV(\n",
    "#         estimator=model, param_distributions=param_dist, n_iter=10, cv=3)\n",
    "#     random_search_result = random_search.fit(X_train_reshaped, y_train)\n",
    "\n",
    "\n",
    "#     # Get the best parameters and best model from RandomizedSearchCV\n",
    "#     best_params = random_search_result.best_params_\n",
    "#     best_model = random_search_result.best_estimator_\n",
    "\n",
    "#     # Save the best model in Keras format\n",
    "#     best_model.model.save(model_file)\n",
    "\n",
    "#     # Evaluate on test data\n",
    "#     score = best_model.score(X_test_reshaped, y_test)\n",
    "#     print(f'Test score: {score}')\n",
    "\n",
    "best_params = {'units': 50, 'learning_rate': 0.01, 'epochs': 50, 'dropout_rate': 0.2, 'batch_size': 10}\n",
    "\n",
    "if os.path.exists(model_file):\n",
    "    best_model = load_model(model_file)\n",
    "else:\n",
    "    best_model = KerasRegressor(model=create_model, learning_rate=best_params['learning_rate'], units=best_params['units'],\n",
    "                            dropout_rate=best_params['dropout_rate'], epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=2)\n",
    "\n",
    "log_resource_usage(\"Pre Training\", False)\n",
    "best_model.fit(X_train_reshaped, y_train)\n",
    "log_resource_usage(\"Post Training\", True)\n",
    "best_model.model.save(model_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame({\n",
    "    'Amount': [1800],\n",
    "    'Transaction Category': ['transport'],\n",
    "    'Year': [2019],\n",
    "    'Month': [5],\n",
    "    'Day': [15],\n",
    "    'Age': [25],\n",
    "    'Inflation Rate': [0.03],\n",
    "    'Dependent Family Size': [3],\n",
    "    'Last Month Budget': [197000],\n",
    "    'Estimated Monthly Expenses': [200000],\n",
    "    'Cumulative Monthly Spending': [56000],\n",
    "    'Average Monthly Budget': [110000]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transform the new data point in the same way as the training data\n",
    "new_data_transformed = preprocessor.transform(new_data)\n",
    "\n",
    "# Perform prediction\n",
    "predicted_budget = loaded_model.predict(new_data_transformed)\n",
    "\n",
    "print(f'Predicted budget: {predicted_budget[0]}')\n",
    "actual_prediction = (predicted_budget * std_budget) + mean_budget\n",
    "\n",
    "# Display the actual predicted Budget value\n",
    "print(f'The actual predicted Budget value is: {np.round(actual_prediction, 2)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bank-data-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
