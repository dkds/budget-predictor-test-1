{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3080 Laptop GPU\n",
      "['../data/generated/generated_data_2.csv', '../data/generated/generated_data_3.csv', '../data/generated/generated_data_1.csv']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 32404 entries, 0 to 10854\n",
      "Data columns (total 20 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   Date                              32404 non-null  object \n",
      " 1   Transaction Category              32404 non-null  object \n",
      " 2   Amount                            32404 non-null  float64\n",
      " 3   Credit/Debit                      32404 non-null  object \n",
      " 4   Payment Method                    32404 non-null  object \n",
      " 5   Inflation Rate                    32404 non-null  float64\n",
      " 6   Dependent Family Size             32404 non-null  int64  \n",
      " 7   Age                               32404 non-null  int64  \n",
      " 8   Months with Higher Spending       32404 non-null  object \n",
      " 9   Number of Expenses a Month        32404 non-null  int64  \n",
      " 10  Most Frequent Expense Categories  32404 non-null  object \n",
      " 11  Estimated Monthly Expenses        32404 non-null  int64  \n",
      " 12  Day                               32404 non-null  int64  \n",
      " 13  Month                             32404 non-null  int64  \n",
      " 14  Year                              32404 non-null  int64  \n",
      " 15  Year-Month                        32404 non-null  object \n",
      " 16  Budget                            32404 non-null  float64\n",
      " 17  Cumulative Monthly Spending       32404 non-null  float64\n",
      " 18  Last Month Budget                 32404 non-null  float64\n",
      " 19  Average Monthly Budget            32404 non-null  float64\n",
      "dtypes: float64(6), int64(7), object(7)\n",
      "memory usage: 5.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import psutil\n",
    "import GPUtil\n",
    "import time\n",
    "\n",
    "gpu = GPUtil.getGPUs()[0]\n",
    "print(gpu.name)\n",
    "\n",
    "start_time = 0\n",
    "\n",
    "\n",
    "def log_resource_usage(scenario, timer_end):\n",
    "    global start_time\n",
    "    cpu_percent = psutil.cpu_percent(interval=1)\n",
    "    ram_mb = psutil.virtual_memory().used / (1024 ** 2)\n",
    "    gpu_usage = gpu.load * 100\n",
    "    gpu_ram_usage = gpu.memoryUsed\n",
    "    print(f\"{scenario}: CPU Usage: {cpu_percent}%\")\n",
    "    print(f\"{scenario}: RAM Usage: {round(ram_mb, 2)} MB\")\n",
    "    print(f\"{scenario}: GPU Usage: {round(gpu_usage, 2)}%\")\n",
    "    print(f\"{scenario}: GPU RAM Usage: {round(gpu_ram_usage, 2)} MB\")\n",
    "    if timer_end:\n",
    "        print(\n",
    "            f\"{scenario}: Execution time: {round(time.time() - start_time, 2)} seconds\")\n",
    "        start_time = 0\n",
    "    elif start_time == 0:\n",
    "        start_time = time.time()\n",
    "    return cpu_percent, ram_mb\n",
    "\n",
    "all_files = glob.glob(os.path.join('../data/generated/' , \"generated_*.csv\"))\n",
    "print(all_files)\n",
    "\n",
    "dataset = pd.DataFrame()\n",
    "for idx, filename in enumerate(all_files):\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    dataset = pd.concat([dataset, df])\n",
    "\n",
    "print(dataset.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207458.55789408716\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 32404 entries, 0 to 10854\n",
      "Data columns (total 12 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Transaction Category         32404 non-null  object \n",
      " 1   Amount                       32404 non-null  float64\n",
      " 2   Inflation Rate               32404 non-null  float64\n",
      " 3   Dependent Family Size        32404 non-null  int64  \n",
      " 4   Age                          32404 non-null  int64  \n",
      " 5   Estimated Monthly Expenses   32404 non-null  int64  \n",
      " 6   Day                          32404 non-null  float64\n",
      " 7   Month                        32404 non-null  float64\n",
      " 8   Year                         32404 non-null  float64\n",
      " 9   Cumulative Monthly Spending  32404 non-null  float64\n",
      " 10  Last Month Budget            32404 non-null  float64\n",
      " 11  Average Monthly Budget       32404 non-null  float64\n",
      "dtypes: float64(8), int64(3), object(1)\n",
      "memory usage: 3.2+ MB\n",
      "None\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index: 32404 entries, 0 to 10854\n",
      "Series name: Budget\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "32404 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 506.3 KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/miniconda3/envs/final-project/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/neo/miniconda3/envs/final-project/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/neo/miniconda3/envs/final-project/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/neo/miniconda3/envs/final-project/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/neo/miniconda3/envs/final-project/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/neo/miniconda3/envs/final-project/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Assume df is your DataFrame\n",
    "X = dataset.drop(['Budget', 'Date', 'Year-Month', 'Credit/Debit', 'Most Frequent Expense Categories',\n",
    "                 'Months with Higher Spending', 'Number of Expenses a Month', 'Payment Method'], axis=1)  # Features\n",
    "y = dataset['Budget']  # Labels\n",
    "\n",
    "# Perform Z-score normalization\n",
    "numeric_cols = ['Amount', 'Month', 'Year', 'Day', 'Last Month Budget',\n",
    "                'Cumulative Monthly Spending', 'Average Monthly Budget']\n",
    "for col in numeric_cols:\n",
    "    X[col] = (X[col] - X[col].mean()) / X[col].std()\n",
    "\n",
    "# If you want to normalize the label as well\n",
    "mean_budget = y.mean()\n",
    "std_budget = y.std()\n",
    "y = (y - mean_budget) / std_budget\n",
    "print(mean_budget)\n",
    "print(X.info())\n",
    "print(y.info())\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Create ColumnTransformer to apply OneHotEncoding only to the 'Description' column\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('desc_onehot', onehot_encoder, ['Transaction Category'])\n",
    "    ],\n",
    "    remainder='passthrough'  # keep remaining columns as is\n",
    ")\n",
    "\n",
    "# Fit and transform the training data and transform testing data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# X_train_onehot and X_test_onehot now contain the one-hot encoded 'Description' column along with other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17,)\n",
      "INFO:tensorflow:Reloading Tuner from ./untitled_project/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre Training: CPU Usage: 0.6%\n",
      "Pre Training: RAM Usage: 4136.39 MB\n",
      "Pre Training: GPU Usage: 0.0%\n",
      "Pre Training: GPU RAM Usage: 708.0 MB\n",
      "Epoch 1/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.2788\n",
      "Epoch 2/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.1324\n",
      "Epoch 3/50\n",
      "811/811 [==============================] - 1s 980us/step - loss: 0.1114\n",
      "Epoch 4/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.1006\n",
      "Epoch 5/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0911\n",
      "Epoch 6/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0852\n",
      "Epoch 7/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0792\n",
      "Epoch 8/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0751\n",
      "Epoch 9/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0713\n",
      "Epoch 10/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0694\n",
      "Epoch 11/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0663\n",
      "Epoch 12/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0656\n",
      "Epoch 13/50\n",
      "811/811 [==============================] - 1s 975us/step - loss: 0.0638\n",
      "Epoch 14/50\n",
      "811/811 [==============================] - 1s 974us/step - loss: 0.0624\n",
      "Epoch 15/50\n",
      "811/811 [==============================] - 1s 991us/step - loss: 0.0613\n",
      "Epoch 16/50\n",
      "811/811 [==============================] - 1s 968us/step - loss: 0.0602\n",
      "Epoch 17/50\n",
      "811/811 [==============================] - 1s 975us/step - loss: 0.0592\n",
      "Epoch 18/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0579\n",
      "Epoch 19/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0565\n",
      "Epoch 20/50\n",
      "811/811 [==============================] - 1s 983us/step - loss: 0.0556\n",
      "Epoch 21/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0558\n",
      "Epoch 22/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0546\n",
      "Epoch 23/50\n",
      "811/811 [==============================] - 1s 995us/step - loss: 0.0534\n",
      "Epoch 24/50\n",
      "811/811 [==============================] - 1s 982us/step - loss: 0.0530\n",
      "Epoch 25/50\n",
      "811/811 [==============================] - 1s 966us/step - loss: 0.0526\n",
      "Epoch 26/50\n",
      "811/811 [==============================] - 1s 961us/step - loss: 0.0520\n",
      "Epoch 27/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0516\n",
      "Epoch 28/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0511\n",
      "Epoch 29/50\n",
      "811/811 [==============================] - 1s 990us/step - loss: 0.0508\n",
      "Epoch 30/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0501\n",
      "Epoch 31/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0501\n",
      "Epoch 32/50\n",
      "811/811 [==============================] - 1s 994us/step - loss: 0.0509\n",
      "Epoch 33/50\n",
      "811/811 [==============================] - 1s 983us/step - loss: 0.0487\n",
      "Epoch 34/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0487\n",
      "Epoch 35/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0493\n",
      "Epoch 36/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0490\n",
      "Epoch 37/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0481\n",
      "Epoch 38/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0460\n",
      "Epoch 39/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0465\n",
      "Epoch 40/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0468\n",
      "Epoch 41/50\n",
      "811/811 [==============================] - 1s 989us/step - loss: 0.0459\n",
      "Epoch 42/50\n",
      "811/811 [==============================] - 1s 980us/step - loss: 0.0460\n",
      "Epoch 43/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0455\n",
      "Epoch 44/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0452\n",
      "Epoch 45/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0443\n",
      "Epoch 46/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0440\n",
      "Epoch 47/50\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 0.0439\n",
      "Epoch 48/50\n",
      "811/811 [==============================] - 1s 979us/step - loss: 0.0441\n",
      "Epoch 49/50\n",
      "811/811 [==============================] - 1s 994us/step - loss: 0.0425\n",
      "Epoch 50/50\n",
      "811/811 [==============================] - 1s 967us/step - loss: 0.0424\n",
      "Post Training: CPU Usage: 2.7%\n",
      "Post Training: RAM Usage: 3972.45 MB\n",
      "Post Training: GPU Usage: 0.0%\n",
      "Post Training: GPU RAM Usage: 708.0 MB\n",
      "Post Training: Execution time: 42.58 seconds\n",
      "203/203 [==============================] - 0s 763us/step\n",
      "Best Hyperparameters: {'input_units': 256}\n",
      "Mean Squared Error with Best Hyperparameters: 0.04480192194308532\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "# Assume preprocessed X_train_transformed, X_test_transformed, y_train, y_test\n",
    "\n",
    "# Standardize the data\n",
    "scaler_x = StandardScaler().fit(X_train_transformed)\n",
    "scaler_y = StandardScaler().fit(y_train.values.reshape(-1, 1))\n",
    "\n",
    "X_train_scaled = scaler_x.transform(X_train_transformed)\n",
    "X_test_scaled = scaler_x.transform(X_test_transformed)\n",
    "y_train_scaled = scaler_y.transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "print((X_train_scaled.shape[1],))\n",
    "\n",
    "# Define the hypermodel\n",
    "def build_hypermodel(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('input_units', min_value=32, max_value=256, step=32),\n",
    "                    activation='relu',\n",
    "                    input_shape=(X_train_scaled.shape[1],),\n",
    "                    \n",
    "                    ))\n",
    "    # model.add(Dropout(rate=hp.Float('input_dropout', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Additional hidden layer with regularization\n",
    "    # model.add(Dense(units=hp.Int('hidden_units', min_value=32, max_value=128, step=32),\n",
    "    #                 activation='relu',\n",
    "    #                 kernel_regularizer=l1_l2(l1=hp.Float('l1_value', min_value=1e-5, max_value=1e-2, sampling='LOG'),\n",
    "    #                                          l2=hp.Float('l2_value', min_value=1e-5, max_value=1e-2, sampling='LOG'))\n",
    "    #                 ))\n",
    "    # model.add(Dropout(rate=hp.Float('hidden_dropout', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = RandomSearch(\n",
    "    build_hypermodel,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=5\n",
    ")\n",
    "\n",
    "# Perform hyperparameter search\n",
    "tuner.search(X_train_scaled, y_train_scaled, epochs=50, validation_split=0.2)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "best_model = tuner.hypermodel.build(best_hp)\n",
    "log_resource_usage(\"Pre Training\", False)\n",
    "best_model.fit(X_train_scaled, y_train_scaled, epochs=50, batch_size=32)\n",
    "log_resource_usage(\"Post Training\", True)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_scaled = best_model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test_scaled, y_pred_scaled)\n",
    "\n",
    "print(f'Best Hyperparameters: {best_hp.values}')\n",
    "print(f'Mean Squared Error with Best Hyperparameters: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame({\n",
    "    'Amount': [1800],\n",
    "    'Transaction Category': ['transport'],\n",
    "    'Year': [2019],\n",
    "    'Month': [5],\n",
    "    'Day': [15],\n",
    "    'Age': [25],\n",
    "    'Inflation Rate': [0.03],\n",
    "    'Dependent Family Size': [3],\n",
    "    'Last Month Budget': [197000],\n",
    "    'Estimated Monthly Expenses': [200000],\n",
    "    'Cumulative Monthly Spending': [56000],\n",
    "    'Average Monthly Budget': [110000]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[188874.7]]\n",
      "Predicted budget: 188874.703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/miniconda3/envs/final-project/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/neo/miniconda3/envs/final-project/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Transform the new data point in the same way as the training data\n",
    "new_data_transformed = preprocessor.transform(new_data)\n",
    "new_data_scaled = scaler_x.transform(new_data_transformed)  # Scale the features\n",
    "\n",
    "# Predict the Budget using the trained neural network model\n",
    "predicted_budget_scaled = best_model.predict(new_data_scaled)\n",
    "\n",
    "# Inverse scale the predicted Budget\n",
    "predicted_budget = scaler_y.inverse_transform(predicted_budget_scaled)\n",
    "\n",
    "print(predicted_budget)\n",
    "\n",
    "print(f'Predicted budget: {round(predicted_budget[0][0], 2)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bank-data-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
